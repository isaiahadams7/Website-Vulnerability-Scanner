import requests
from bs4 import BeautifulSoup
import torch
from sklearn.feature_extraction.text import TfidfVectorizer
import numpy as np
import pickle
import re
from train_model import VulnerabilityModel


def load_model_and_vectorizer(model_path, vectorizer_path, input_size_path):
    # Load the input size
    with open(input_size_path, 'rb') as f:
        input_size = pickle.load(f)

    # Load the trained model
    model = VulnerabilityModel(input_size)
    model.load_state_dict(torch.load(model_path))
    model.eval()

    # Load the TF-IDF vectorizer
    with open(vectorizer_path, 'rb') as f:
        vectorizer = pickle.load(f)

    return model, vectorizer


def analyze_html(html_content):
    """
    Analyze HTML to identify specific parts that might be vulnerable and include line numbers.
    """
    soup = BeautifulSoup(html_content, 'html.parser')
    vulnerabilities = []

    # Split the HTML content into lines for line tracking
    lines = html_content.split('\n')

    # Check for forms that might be vulnerable to SQL Injection
    forms = soup.find_all('form')
    for form in forms:
        form_line_number = get_line_number(str(form), html_content, lines)
        action = form.get('action')
        inputs = form.find_all('input')
        form_details = f"Form action: {action}, Inputs: {[input.get('name') for input in inputs]}"
        vulnerabilities.append(f"Potential SQL Injection in form: {form_details} at line {form_line_number}")

    # Check for scripts that might be vulnerable to XSS
    scripts = soup.find_all('script')
    for script in scripts:
        if script.string:
            script_line_number = get_line_number(str(script), html_content, lines)
            script_content = script.string.strip()
            vulnerabilities.append(f"Potential XSS in script: {script_content[:30]}... at line {script_line_number}")

    return vulnerabilities


def get_line_number(tag_str, html_content, lines):
    """
    Find the line number of a tag in the HTML content.
    """
    start_index = html_content.find(tag_str)
    if start_index == -1:
        return -1  # Tag not found
    # Count the number of newlines up to the start_index to find the line number
    line_number = html_content.count('\n', 0, start_index) + 1
    return line_number


def scan_website(url, model, vectorizer):
    response = requests.get(url)
    html_content = response.text

    # Extract text from the HTML to use as features
    soup = BeautifulSoup(html_content, 'html.parser')
    text = ' '.join(soup.stripped_strings)

    # Vectorize the text using the TF-IDF vectorizer
    text_tfidf = vectorizer.transform([text]).toarray()

    # Convert to PyTorch tensor
    text_tensor = torch.tensor(text_tfidf, dtype=torch.float32)

    # Predict vulnerabilities using the model
    with torch.no_grad():
        output = model(text_tensor)
        _, predicted = torch.max(output, 1)

    severity_map = {0: 'low', 1: 'medium', 2: 'high', 3: 'critical'}
    predicted_severity = severity_map[predicted.item()]

    # Analyze HTML for specific vulnerabilities
    detailed_vulnerabilities = analyze_html(html_content)

    scan_output = f'Predicted vulnerability severity for {url}: {predicted_severity}\n'
    scan_output += 'Detailed vulnerability analysis:\n'
    for vuln in detailed_vulnerabilities:
        scan_output += f' - {vuln}\n'

    # Save the scan output to a file
    with open('scan_output.txt', 'w') as file:
        file.write(scan_output)

    return scan_output


def read_scan_output(file_path):
    """
    Read the scan output from a file and return a list of vulnerabilities with their details.
    """
    with open(file_path, 'r') as file:
        scan_output = file.read()

    vulnerabilities = []
    lines = scan_output.split('\n')

    for line in lines:
        sql_injection_match = re.search(r'Potential SQL Injection in form: (.+) at line (\d+)', line)
        xss_match = re.search(r'Potential XSS in script: (.+) at line (\d+)', line)

        if sql_injection_match:
            vulnerabilities.append({
                'type': 'SQL Injection',
                'details': sql_injection_match.group(1),
                'line': sql_injection_match.group(2)
            })
        elif xss_match:
            vulnerabilities.append({
                'type': 'XSS',
                'details': xss_match.group(1),
                'line': xss_match.group(2)
            })

    return vulnerabilities


def provide_exploit_advice(vulnerabilities):
    """
    Provide advice on how to exploit the identified vulnerabilities.
    """
    for vuln in vulnerabilities:
        if vuln['type'] == 'SQL Injection':
            print(f"\nExploit Advice for SQL Injection (Line {vuln['line']}):")
            print(f" - Form Details: {vuln['details']}")
            print(" - Try injecting SQL commands into input fields.")
            print(" - Example payload: ' OR '1'='1")
            print(" - Use tools like sqlmap for automated exploitation.")

        elif vuln['type'] == 'XSS':
            print(f"\nExploit Advice for XSS (Line {vuln['line']}):")
            print(f" - Script Details: {vuln['details']}")
            print(" - Try injecting JavaScript into input fields that are reflected in the output.")
            print(" - Example payload: <script>alert('XSS');</script>")
            print(" - Use tools like XSS Hunter for advanced exploitation.")


def main():
    url = 'http://scanme.nmap.org'  # Replace with the URL you want to scan
    model_path = 'vulnerability_model.pth'
    vectorizer_path = 'tfidf_vectorizer.pkl'
    input_size_path = 'input_size.pkl'

    model, vectorizer = load_model_and_vectorizer(model_path, vectorizer_path, input_size_path)
    scan_output = scan_website(url, model, vectorizer)
    print(scan_output)  # Print scan output for verification

    # Read the scan output from the file and provide exploit advice
    vulnerabilities = read_scan_output('scan_output.txt')
    provide_exploit_advice(vulnerabilities)


if __name__ == '__main__':
    main()
